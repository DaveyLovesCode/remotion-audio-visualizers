<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audio Analyzer</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: #0a0a0f;
      color: #fff;
      padding: 40px;
      max-width: 800px;
      margin: 0 auto;
    }
    h1 { color: #ff00ff; margin-bottom: 10px; }
    p { color: #888; margin-bottom: 30px; }
    .drop-zone {
      border: 2px dashed #444;
      border-radius: 12px;
      padding: 60px;
      text-align: center;
      margin-bottom: 30px;
      transition: all 0.2s;
    }
    .drop-zone:hover, .drop-zone.drag-over {
      border-color: #ff00ff;
      background: rgba(255, 0, 255, 0.05);
    }
    .drop-zone input { display: none; }
    .drop-zone label {
      cursor: pointer;
      display: block;
    }
    .drop-zone h2 { margin: 0 0 10px; color: #fff; }
    .drop-zone span { color: #666; }
    .progress {
      background: #1a1a2e;
      border-radius: 8px;
      height: 20px;
      overflow: hidden;
      margin-bottom: 20px;
      display: none;
    }
    .progress-bar {
      background: linear-gradient(90deg, #ff00ff, #00ffff);
      height: 100%;
      width: 0%;
      transition: width 0.1s;
    }
    .status {
      padding: 20px;
      background: #1a1a2e;
      border-radius: 8px;
      margin-bottom: 20px;
      display: none;
    }
    .status.visible { display: block; }
    .status h3 { margin: 0 0 10px; color: #00ffff; }
    .status pre {
      background: #0a0a15;
      padding: 15px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 12px;
    }
    button {
      background: linear-gradient(135deg, #ff00ff, #8000ff);
      border: none;
      color: #fff;
      padding: 15px 30px;
      border-radius: 8px;
      font-size: 16px;
      cursor: pointer;
      display: none;
    }
    button:hover { opacity: 0.9; }
    button.visible { display: inline-block; }
    canvas {
      width: 100%;
      height: 100px;
      background: #1a1a2e;
      border-radius: 8px;
      margin-bottom: 20px;
      display: none;
    }
    canvas.visible { display: block; }
  </style>
</head>
<body>
  <h1>ðŸŽµ Audio Analyzer</h1>
  <p>Analyze your audio file to generate frame-by-frame frequency data for the visualizer.</p>

  <div class="drop-zone" id="dropZone">
    <label for="audioFile">
      <h2>Drop audio file here</h2>
      <span>or click to browse (MP3, WAV, OGG)</span>
    </label>
    <input type="file" id="audioFile" accept="audio/*">
  </div>

  <canvas id="waveform" class=""></canvas>

  <div class="progress" id="progress">
    <div class="progress-bar" id="progressBar"></div>
  </div>

  <div class="status" id="status">
    <h3>Analysis Complete!</h3>
    <pre id="stats"></pre>
  </div>

  <button id="downloadBtn" class="">Download audioAnalysis.json</button>

  <script>
    const FPS = 30;
    let analysisResult = null;

    const dropZone = document.getElementById('dropZone');
    const audioFile = document.getElementById('audioFile');
    const waveform = document.getElementById('waveform');
    const progress = document.getElementById('progress');
    const progressBar = document.getElementById('progressBar');
    const status = document.getElementById('status');
    const stats = document.getElementById('stats');
    const downloadBtn = document.getElementById('downloadBtn');

    // Drag and drop handling
    ['dragenter', 'dragover'].forEach(event => {
      dropZone.addEventListener(event, (e) => {
        e.preventDefault();
        dropZone.classList.add('drag-over');
      });
    });

    ['dragleave', 'drop'].forEach(event => {
      dropZone.addEventListener(event, (e) => {
        e.preventDefault();
        dropZone.classList.remove('drag-over');
      });
    });

    dropZone.addEventListener('drop', (e) => {
      const file = e.dataTransfer.files[0];
      if (file) processFile(file);
    });

    audioFile.addEventListener('change', (e) => {
      const file = e.target.files[0];
      if (file) processFile(file);
    });

    async function processFile(file) {
      progress.style.display = 'block';
      progressBar.style.width = '10%';

      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const arrayBuffer = await file.arrayBuffer();

      progressBar.style.width = '30%';

      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

      progressBar.style.width = '50%';

      // Draw waveform
      drawWaveform(audioBuffer);

      // Analyze
      analysisResult = await analyzeAudio(audioBuffer, audioContext);

      progressBar.style.width = '100%';

      // Show stats
      stats.textContent = JSON.stringify({
        duration: `${audioBuffer.duration.toFixed(2)}s`,
        sampleRate: audioBuffer.sampleRate,
        channels: audioBuffer.numberOfChannels,
        totalFrames: analysisResult.frames.length,
        fps: FPS,
        estimatedBPM: analysisResult.bpm,
        beatCount: analysisResult.frames.filter(f => f.isBeat).length
      }, null, 2);

      status.classList.add('visible');
      downloadBtn.classList.add('visible');

      setTimeout(() => {
        progress.style.display = 'none';
      }, 500);
    }

    function drawWaveform(audioBuffer) {
      waveform.classList.add('visible');
      const ctx = waveform.getContext('2d');
      const data = audioBuffer.getChannelData(0);
      const width = waveform.width = waveform.offsetWidth * 2;
      const height = waveform.height = 200;

      ctx.fillStyle = '#1a1a2e';
      ctx.fillRect(0, 0, width, height);

      ctx.strokeStyle = '#ff00ff';
      ctx.lineWidth = 1;
      ctx.beginPath();

      const step = Math.ceil(data.length / width);
      for (let i = 0; i < width; i++) {
        const idx = i * step;
        const val = data[idx] || 0;
        const y = (val + 1) / 2 * height;
        if (i === 0) ctx.moveTo(i, y);
        else ctx.lineTo(i, y);
      }
      ctx.stroke();
    }

    async function analyzeAudio(audioBuffer, audioContext) {
      const duration = audioBuffer.duration;
      const totalFrames = Math.ceil(duration * FPS);
      const sampleRate = audioBuffer.sampleRate;
      const samplesPerFrame = Math.floor(sampleRate / FPS);

      // Create offline context for analysis
      const offlineContext = new OfflineAudioContext(
        1,
        audioBuffer.length,
        sampleRate
      );

      const source = offlineContext.createBufferSource();
      source.buffer = audioBuffer;

      const analyser = offlineContext.createAnalyser();
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.3;

      source.connect(analyser);
      analyser.connect(offlineContext.destination);

      const frequencyData = new Uint8Array(analyser.frequencyBinCount);
      const frames = [];

      // We'll analyze in chunks since OfflineAudioContext doesn't support real-time analysis
      // Instead, we'll process the raw data directly
      const rawData = audioBuffer.getChannelData(0);

      for (let frameIndex = 0; frameIndex < totalFrames; frameIndex++) {
        if (frameIndex % 100 === 0) {
          progressBar.style.width = `${50 + (frameIndex / totalFrames) * 45}%`;
          await new Promise(r => setTimeout(r, 0)); // Let UI update
        }

        const startSample = frameIndex * samplesPerFrame;
        const endSample = Math.min(startSample + 2048, rawData.length);
        const frameSamples = rawData.slice(startSample, endSample);

        // Simple FFT-like frequency analysis using DCT approximation
        const freqBands = analyzeFrequencies(frameSamples);

        // Energy calculation
        let energy = 0;
        for (let i = 0; i < frameSamples.length; i++) {
          energy += frameSamples[i] * frameSamples[i];
        }
        energy = Math.sqrt(energy / frameSamples.length);

        // Beat detection
        const isBeat = frameIndex > 0 &&
          freqBands.bass > 0.25 &&
          freqBands.bass > (frames[frameIndex - 1]?.bass ?? 0) * 1.3;

        frames.push({
          bass: Math.min(1, freqBands.bass),
          lowMid: Math.min(1, freqBands.lowMid),
          mid: Math.min(1, freqBands.mid),
          highMid: Math.min(1, freqBands.highMid),
          high: Math.min(1, freqBands.high),
          energy: Math.min(1, energy * 4),
          isBeat,
          beatIntensity: isBeat ? Math.min(1, freqBands.bass * 2) : 0
        });
      }

      // Estimate BPM
      const beatFrames = frames.map((f, i) => f.isBeat ? i : -1).filter(i => i >= 0);
      let bpm = 128;
      if (beatFrames.length > 4) {
        const intervals = [];
        for (let i = 1; i < Math.min(beatFrames.length, 50); i++) {
          intervals.push(beatFrames[i] - beatFrames[i - 1]);
        }
        const avgInterval = intervals.reduce((a, b) => a + b, 0) / intervals.length;
        bpm = Math.round((60 * FPS) / avgInterval);
        if (bpm < 60) bpm *= 2;
        if (bpm > 200) bpm /= 2;
      }

      return { bpm, frames };
    }

    function analyzeFrequencies(samples) {
      // Simple frequency band energy calculation
      // For more accurate results, implement proper FFT
      const n = samples.length;

      // Low frequency components (bass) - sum of low-frequency energy
      let bass = 0, lowMid = 0, mid = 0, highMid = 0, high = 0;

      // Simple approach: analyze sample differences at different rates
      for (let i = 1; i < n; i++) {
        const diff = Math.abs(samples[i] - samples[i-1]);

        // Weight different "frequencies" based on sample distance patterns
        if (i % 16 === 0) bass += Math.abs(samples[i]) * 2;
        if (i % 8 === 0) lowMid += Math.abs(samples[i]) * 1.5;
        if (i % 4 === 0) mid += Math.abs(samples[i]);
        if (i % 2 === 0) highMid += diff * 0.8;
        high += diff * diff * 0.5;
      }

      const scale = n / 2048;
      return {
        bass: (bass / (n / 16)) * scale * 3,
        lowMid: (lowMid / (n / 8)) * scale * 2.5,
        mid: (mid / (n / 4)) * scale * 2,
        highMid: (highMid / (n / 2)) * scale * 1.5,
        high: Math.sqrt(high / n) * scale * 3
      };
    }

    downloadBtn.addEventListener('click', () => {
      if (!analysisResult) return;

      const blob = new Blob([JSON.stringify(analysisResult, null, 2)], { type: 'application/json' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = 'audioAnalysis.json';
      a.click();
      URL.revokeObjectURL(url);
    });
  </script>
</body>
</html>
